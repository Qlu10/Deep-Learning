{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection \n",
    "by  Yu Chi Chen, Chong Zhao, Zihan Chen, Qiuchen Lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this chunk, we import necessary packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.layers import Dropout\n",
    "import keras.backend as K\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a new loss function that penalize more on the failure of identifying fraud transcation\n",
    "def lossfunction(y_true, y_pred):\n",
    "    if y_true==0:\n",
    "        return K.square(y_pred - y_true)\n",
    "    else:\n",
    "        return 25*K.square(y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct neural network using keras\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(30,), activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(70, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "#model.compile(loss='mse', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.compile(loss=[lossfunction], optimizer=\"Nadam\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and preprocess the data\n",
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "X=df.drop(['Class'],axis=1)\n",
    "y=df.Class\n",
    "# We stratify by the label while spliting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "# It's a unblanced data so we use smote to do the oversampling\n",
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "# We use robust scaler to standardize the data\n",
    "transformer = RobustScaler().fit(X_train)\n",
    "X_train=transformer.transform(X_train)\n",
    "X_test=transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 454902 samples, validate on 56962 samples\n",
      "Epoch 1/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.1972 - accuracy: 0.9901 - val_loss: 0.0678 - val_accuracy: 0.9968\n",
      "Epoch 2/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0794 - accuracy: 0.9962 - val_loss: 0.0426 - val_accuracy: 0.9979\n",
      "Epoch 3/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0582 - accuracy: 0.9972 - val_loss: 0.0370 - val_accuracy: 0.9984\n",
      "Epoch 4/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0464 - accuracy: 0.9977 - val_loss: 0.0509 - val_accuracy: 0.9978\n",
      "Epoch 5/30\n",
      "454902/454902 [==============================] - 17s 37us/step - loss: 0.0440 - accuracy: 0.9979 - val_loss: 0.0361 - val_accuracy: 0.9983\n",
      "Epoch 6/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0395 - accuracy: 0.9982 - val_loss: 0.0524 - val_accuracy: 0.9978\n",
      "Epoch 7/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0389 - accuracy: 0.9983 - val_loss: 0.0360 - val_accuracy: 0.9984\n",
      "Epoch 8/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0348 - accuracy: 0.9984 - val_loss: 0.0440 - val_accuracy: 0.9981\n",
      "Epoch 9/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0351 - accuracy: 0.9984 - val_loss: 0.0260 - val_accuracy: 0.9989\n",
      "Epoch 10/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0316 - accuracy: 0.9986 - val_loss: 0.0262 - val_accuracy: 0.9989\n",
      "Epoch 11/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0325 - accuracy: 0.9985 - val_loss: 0.0376 - val_accuracy: 0.9984\n",
      "Epoch 12/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0312 - accuracy: 0.9986 - val_loss: 0.0300 - val_accuracy: 0.9987\n",
      "Epoch 13/30\n",
      "454902/454902 [==============================] - 17s 37us/step - loss: 0.0293 - accuracy: 0.9986 - val_loss: 0.0308 - val_accuracy: 0.9987\n",
      "Epoch 14/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0305 - accuracy: 0.9986 - val_loss: 0.0344 - val_accuracy: 0.9986\n",
      "Epoch 15/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 0.0299 - val_accuracy: 0.9986\n",
      "Epoch 16/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0265 - accuracy: 0.9988 - val_loss: 0.0319 - val_accuracy: 0.9985\n",
      "Epoch 17/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 0.0414 - val_accuracy: 0.9983\n",
      "Epoch 18/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0285 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9988\n",
      "Epoch 19/30\n",
      "454902/454902 [==============================] - 16s 36us/step - loss: 0.0242 - accuracy: 0.9989 - val_loss: 0.0272 - val_accuracy: 0.9988\n",
      "Epoch 20/30\n",
      "454902/454902 [==============================] - 83s 182us/step - loss: 0.0262 - accuracy: 0.9989 - val_loss: 0.0283 - val_accuracy: 0.9988\n",
      "Epoch 21/30\n",
      "454902/454902 [==============================] - 17s 38us/step - loss: 0.0240 - accuracy: 0.9989 - val_loss: 0.0274 - val_accuracy: 0.9988\n",
      "Epoch 22/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0276 - accuracy: 0.9988 - val_loss: 0.0256 - val_accuracy: 0.9989\n",
      "Epoch 23/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 0.0274 - val_accuracy: 0.9988\n",
      "Epoch 24/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0249 - accuracy: 0.9989 - val_loss: 0.0293 - val_accuracy: 0.9988\n",
      "Epoch 25/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0215 - accuracy: 0.9991 - val_loss: 0.0260 - val_accuracy: 0.9989\n",
      "Epoch 26/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0283 - accuracy: 0.9988 - val_loss: 0.0304 - val_accuracy: 0.9987\n",
      "Epoch 27/30\n",
      "454902/454902 [==============================] - 17s 36us/step - loss: 0.0251 - accuracy: 0.9989 - val_loss: 0.0271 - val_accuracy: 0.9989\n",
      "Epoch 28/30\n",
      "454902/454902 [==============================] - 17s 37us/step - loss: 0.0258 - accuracy: 0.9989 - val_loss: 0.0296 - val_accuracy: 0.9988\n",
      "Epoch 29/30\n",
      "454902/454902 [==============================] - 18s 40us/step - loss: 0.0287 - accuracy: 0.9988 - val_loss: 0.0266 - val_accuracy: 0.9989\n",
      "Epoch 30/30\n",
      "454902/454902 [==============================] - 17s 38us/step - loss: 0.0260 - accuracy: 0.9989 - val_loss: 0.0302 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "#Train our model\n",
    "model.fit(X_train,y_train, epochs = 30,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions and set the threshold as 0.5\n",
    "y_pred = model.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]<0.5:\n",
    "        y_pred[i]=0\n",
    "    else:\n",
    "        y_pred[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.9987711105649381\n",
      "Confusion Matrix:\n",
      "[[56800    64]\n",
      " [    6    92]]\n",
      "Classificaiton Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.59      0.94      0.72        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.79      0.97      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "#Accuracy score shows total accuracy on test set\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "#Confusion matrix shows alpha error and beta error, and we mainly focus on beta error \n",
    "#which is (2,1) in matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#Recall rate on 1 is our final aim because we try to detect fraud data as much as possible\n",
    "#while alpha error can be a little bit higher since in reality, banks could send alerts to\n",
    "#customers. Actually, Terminating suspicious transactions cost much less than \n",
    "#processing fraud transactions from both law and finance perspective\n",
    "print(\"Classificaiton Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model for future use\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
